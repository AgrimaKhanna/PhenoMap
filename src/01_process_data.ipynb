{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.17/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_j/jxp24xt56297mvdmdng0bj600000gn/T/ipykernel_85538/3668935253.py\", line 3, in <module>\n",
      "    import torch\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/libpyg.so, 0x0006): tried: '/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/libpyg.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/libpyg.so' (no such file), '/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/libpyg.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: dlopen(/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_scatter/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: dlopen(/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_cluster/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: dlopen(/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_spline_conv/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEb'\n",
      "  warnings.warn(\n",
      "/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_sparse/_version_cpu.so, 0x0006): tried: '/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_sparse/_version_cpu.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_sparse/_version_cpu.so' (no such file), '/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/torch_sparse/_version_cpu.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/Users/agrimakhanna/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib \n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData\n",
    "import unicodedata\n",
    "import pickle\n",
    "\n",
    "data_fp = '../data/PROCESSED/'\n",
    "model_fp = '../models'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "pathlib.Path(model_fp).mkdir(parents=True, exist_ok=True)\n",
    "# Create the directory if it doesn't exist\n",
    "pathlib.Path(data_fp).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/jxp24xt56297mvdmdng0bj600000gn/T/ipykernel_85538/3873592471.py:2: DtypeWarning: Columns (3,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(\"../data/RAW/kg.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "df=pd.read_csv(\"../data/RAW/kg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of different node types:\n",
      "type\n",
      "biological_process    28642\n",
      "gene/protein          27671\n",
      "disease               17080\n",
      "effect/phenotype      15311\n",
      "anatomy               14035\n",
      "molecular_function    11169\n",
      "drug                   7957\n",
      "cellular_component     4176\n",
      "pathway                2516\n",
      "exposure                818\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of different edge types:\n",
      "relation\n",
      "anatomy_protein_present       3036406\n",
      "drug_drug                     2672628\n",
      "protein_protein                642150\n",
      "disease_phenotype_positive     300634\n",
      "bioprocess_protein             289610\n",
      "cellcomp_protein               166804\n",
      "disease_protein                160822\n",
      "molfunc_protein                139060\n",
      "drug_effect                    129568\n",
      "bioprocess_bioprocess          105772\n",
      "pathway_protein                 85292\n",
      "disease_disease                 64388\n",
      "contraindication                61350\n",
      "drug_protein                    51306\n",
      "anatomy_protein_absent          39774\n",
      "phenotype_phenotype             37472\n",
      "anatomy_anatomy                 28064\n",
      "molfunc_molfunc                 27148\n",
      "indication                      18776\n",
      "cellcomp_cellcomp                9690\n",
      "phenotype_protein                6660\n",
      "off-label use                    5136\n",
      "pathway_pathway                  5070\n",
      "exposure_disease                 4608\n",
      "exposure_exposure                4140\n",
      "exposure_bioprocess              3250\n",
      "exposure_protein                 2424\n",
      "disease_phenotype_negative       2386\n",
      "exposure_molfunc                   90\n",
      "exposure_cellcomp                  20\n",
      "Name: count, dtype: int64\n",
      "Total unique nodes: 129375\n",
      "Total unique edges: 8100128\n",
      "\n",
      "Unique Relations:\n",
      " relation\n",
      "anatomy_protein_present       3036406\n",
      "drug_drug                     2672628\n",
      "protein_protein                642150\n",
      "disease_phenotype_positive     300634\n",
      "bioprocess_protein             289610\n",
      "cellcomp_protein               166804\n",
      "disease_protein                160822\n",
      "molfunc_protein                139060\n",
      "drug_effect                    129568\n",
      "bioprocess_bioprocess          105772\n",
      "pathway_protein                 85292\n",
      "disease_disease                 64388\n",
      "contraindication                61350\n",
      "drug_protein                    51306\n",
      "anatomy_protein_absent          39774\n",
      "phenotype_phenotype             37472\n",
      "anatomy_anatomy                 28064\n",
      "molfunc_molfunc                 27148\n",
      "indication                      18776\n",
      "cellcomp_cellcomp                9690\n",
      "phenotype_protein                6660\n",
      "off-label use                    5136\n",
      "pathway_pathway                  5070\n",
      "exposure_disease                 4608\n",
      "exposure_exposure                4140\n",
      "exposure_bioprocess              3250\n",
      "exposure_protein                 2424\n",
      "disease_phenotype_negative       2386\n",
      "exposure_molfunc                   90\n",
      "exposure_cellcomp                  20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Node type counts\n",
    "node_types = pd.concat([\n",
    "    df[['x_index', 'x_type']].rename(columns={'x_index': 'index', 'x_type': 'type'}),\n",
    "    df[['y_index', 'y_type']].rename(columns={'y_index': 'index', 'y_type': 'type'})\n",
    "]).drop_duplicates()\n",
    "\n",
    "# Getting the umber of nodes types\n",
    "print(\"\\nNumber of different node types:\")\n",
    "print(node_types['type'].value_counts())\n",
    "\n",
    "# Getting the umber of edge types\n",
    "print(\"\\nNumber of different edge types:\")\n",
    "print(df['relation'].value_counts())\n",
    "\n",
    "# Unique node count using globally unique indices\n",
    "unique_nodes = set(df['x_index']).union(set(df['y_index']))\n",
    "print(\"Total unique nodes:\", len(unique_nodes))\n",
    "\n",
    "# Unique edge count based on (source, target, relation) triplet\n",
    "unique_edges = df[['x_index', 'y_index', 'relation']].drop_duplicates()\n",
    "print(\"Total unique edges:\", len(unique_edges))\n",
    "\n",
    "# Count unique relations\n",
    "unique_relations = df[\"relation\"].value_counts()\n",
    "print(\"\\nUnique Relations:\\n\", unique_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../data/PROCESSED'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(selected_relations)]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save filtered dataframe\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mfiltered_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_fp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/filtered_primekg.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Vanderbilt/Spring2025/AI for CPS/Project/PhenoMap/venv/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../data/PROCESSED'"
     ]
    }
   ],
   "source": [
    "# Relationships to extract\n",
    "selected_relations = [\n",
    "    \"protein_protein\",\n",
    "    \"disease_phenotype_positive\",\n",
    "    \"disease_phenotype_negative\",\n",
    "    \"bioprocess_protein\",\n",
    "    \"disease_protein\",\n",
    "    \"drug_effect\",\n",
    "    \"pathway_protein\",\n",
    "    \"disease_disease\",\n",
    "    \"contraindication\",\n",
    "    \"drug_protein\",\n",
    "    \"indication\",\n",
    "    \"exposure_disease \",\n",
    "    \"anatomy_protein_absent\"\n",
    "]\n",
    "# Filter the dataframe\n",
    "filtered_df = df[df[\"relation\"].isin(selected_relations)]\n",
    "\n",
    "# Save filtered dataframe\n",
    "filtered_df.to_csv(f\"{data_fp}/filtered_primekg.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING THE GRAPH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15022/3803802179.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  edge_index = torch.tensor([src_ids[valid_mask].values, dst_ids[valid_mask].values], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hetero_data and node_maps successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/PROCESSED/filtered_primekg.csv\", low_memory=False)\n",
    "\n",
    "# Clean names\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize(\"NFKD\", str(text)).strip().lower()\n",
    "\n",
    "df[\"x_name\"] = df[\"x_name\"].apply(clean_text)\n",
    "df[\"y_name\"] = df[\"y_name\"].apply(clean_text)\n",
    "\n",
    "# Normalize types\n",
    "node_type_mapping = {\n",
    "    \"gene/protein\": \"protein\",\n",
    "    \"chemical/drug\": \"drug\",\n",
    "    \"drug\": \"drug\",\n",
    "    \"disease\": \"disease\",\n",
    "    \"biological_process\": \"bioprocess\",\n",
    "    \"bioprocess\": \"bioprocess\",\n",
    "    \"pathway\": \"pathway\",\n",
    "    \"effect/phenotype\": \"phenotype\"\n",
    "}\n",
    "df[\"x_type\"] = df[\"x_type\"].map(node_type_mapping)\n",
    "df[\"y_type\"] = df[\"y_type\"].map(node_type_mapping)\n",
    "\n",
    "#  Extract nodes and relations\n",
    "node_sets = {t: set() for t in node_type_mapping.values()}\n",
    "for t in node_sets.keys():\n",
    "    x_nodes = set(df[df[\"x_type\"] == t][\"x_name\"].dropna().unique())\n",
    "    y_nodes = set(df[df[\"y_type\"] == t][\"y_name\"].dropna().unique())\n",
    "    node_sets[t] = x_nodes | y_nodes\n",
    "\n",
    "relation_map = {}\n",
    "actual_relations = set(df[\"relation\"].unique())\n",
    "for rel in actual_relations:\n",
    "    x_type = df[df[\"relation\"] == rel][\"x_type\"].iloc[0]\n",
    "    y_type = df[df[\"relation\"] == rel][\"y_type\"].iloc[0]\n",
    "    if x_type in node_sets and y_type in node_sets:\n",
    "        relation_map[rel] = (x_type, y_type)\n",
    "\n",
    "# Create node maps\n",
    "node_maps = {k: {name: i for i, name in enumerate(sorted(v))} for k, v in node_sets.items()}\n",
    "\n",
    "# Create HeteroData\n",
    "hetero_data = HeteroData()\n",
    "for node_type, name_to_id in node_maps.items():\n",
    "    hetero_data[node_type].num_nodes = len(name_to_id)\n",
    "    hetero_data[node_type].x = torch.randn(len(name_to_id), 128)\n",
    "\n",
    "for rel, (src_type, dst_type) in relation_map.items():\n",
    "    rel_df = df[df['relation'] == rel]\n",
    "    src_ids = rel_df['x_name'].map(node_maps[src_type]).fillna(-1).astype(int)\n",
    "    dst_ids = rel_df['y_name'].map(node_maps[dst_type]).fillna(-1).astype(int)\n",
    "    valid_mask = (src_ids != -1) & (dst_ids != -1)\n",
    "    edge_index = torch.tensor([src_ids[valid_mask].values, dst_ids[valid_mask].values], dtype=torch.long)\n",
    "    hetero_data[(src_type, rel, dst_type)].edge_index = edge_index\n",
    "\n",
    "# Save HeteroData using torch.save (safe)\n",
    "torch.save(hetero_data.to_dict(), f\"{model_fp}/hetero_data_dict_version_final.pt\")\n",
    "\n",
    "# Save node_maps safely with pickle\n",
    "with open(f\"{data_fp}/node_maps_version_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(node_maps, f)\n",
    "\n",
    "print(\"Saved hetero_data and node_maps successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
